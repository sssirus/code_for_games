
[RANK 0] Collecting rollouts
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/inspur/anaconda3/envs/myenv2/lib/python3.10/site-packages/transformers/generation/utils.py:2697: UserWarning: Specified kernel cache directory is not writable! This disables kernel caching. Specified directory is /home/inspur/.cache/torch/kernels. This warning will appear only once per process. (Triggered internally at ../aten/src/ATen/native/cuda/jit_utils.cpp:1461.)
  next_tokens.tile(eos_token_id_tensor.shape[0], 1).ne(eos_token_id_tensor.unsqueeze(1)).prod(dim=0)
[RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:06<00:00,  2.36s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                Evaluation #0 reward/mean: 0.179 metrics/optimality: 0.179
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ bides  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ lozen  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ boo    │ -3.0   │ -3.0       │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[losses/total_loss: 0.40 | losses/policy_loss: -0.11 | losses/value_loss: 0.43]:   0%|                      | 4/800 [00:10<34:14,  2.58s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.28 | losses/policy_loss: -0.09 | losses/value_loss: 0.30]:   1%|▏                     | 8/800 [00:27<44:45,  3.39s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.35 | losses/policy_loss: -0.09 | losses/value_loss: 0.36]:   2%|▎                    | 12/800 [00:48<52:32,  4.00s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.35 | losses/policy_loss: -0.07 | losses/value_loss: 0.35]:   2%|▍                    | 16/800 [01:06<50:13,  3.84s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.30 | losses/policy_loss: -0.08 | losses/value_loss: 0.32]:   2%|▌                    | 20/800 [01:24<47:35,  3.66s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.33 | losses/policy_loss: -0.07 | losses/value_loss: 0.33]:   3%|▋                    | 24/800 [01:43<48:38,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.26 | losses/policy_loss: -0.08 | losses/value_loss: 0.28]:   4%|▋                    | 28/800 [02:03<52:33,  4.08s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.33 | losses/policy_loss: -0.06 | losses/value_loss: 0.32]:   4%|▊                    | 32/800 [02:21<47:36,  3.72s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.22 | losses/policy_loss: -0.07 | losses/value_loss: 0.24]:   4%|▉                    | 36/800 [02:42<51:51,  4.07s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.25 | losses/policy_loss: -0.07 | losses/value_loss: 0.27]:   5%|█                    | 40/800 [03:00<48:54,  3.86s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.23 | losses/policy_loss: -0.07 | losses/value_loss: 0.25]:   6%|█▏                   | 44/800 [03:18<46:10,  3.67s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.07 | losses/value_loss: 0.21]:   6%|█▎                   | 48/800 [03:38<50:53,  4.06s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.25 | losses/policy_loss: -0.07 | losses/value_loss: 0.27]:   6%|█▎                   | 52/800 [03:56<45:12,  3.63s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.31 | losses/policy_loss: -0.06 | losses/value_loss: 0.31]:   7%|█▍                   | 56/800 [04:16<50:13,  4.05s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.07 | losses/value_loss: 0.19]:   8%|█▌                   | 60/800 [04:35<47:32,  3.85s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.34 | losses/policy_loss: -0.07 | losses/value_loss: 0.34]:   8%|█▋                   | 64/800 [04:53<46:40,  3.81s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.07 | losses/value_loss: 0.16]:   8%|█▊                   | 68/800 [05:11<43:26,  3.56s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.07 | losses/value_loss: 0.19]:   9%|█▉                   | 72/800 [05:29<45:19,  3.74s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.15 | losses/policy_loss: -0.06 | losses/value_loss: 0.18]:  10%|█▉                   | 76/800 [05:47<43:53,  3.64s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.28 | losses/policy_loss: -0.06 | losses/value_loss: 0.29]:  10%|██                   | 80/800 [06:05<45:02,  3.75s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.20 | losses/policy_loss: -0.06 | losses/value_loss: 0.22]:  10%|██▏                  | 84/800 [06:24<45:07,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.07 | losses/value_loss: 0.16]:  11%|██▎                  | 88/800 [06:41<42:12,  3.56s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.06 | losses/value_loss: 0.15]:  12%|██▍                  | 92/800 [06:59<42:21,  3.59s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.06 | losses/value_loss: 0.19]:  12%|██▌                  | 96/800 [07:17<42:15,  3.60s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.20 | losses/policy_loss: -0.07 | losses/value_loss: 0.22]:  12%|██▌                  | 99/800 [07:32<48:35,  4.16s/it][RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:07<00:00,  2.37s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                 Evaluation #1 reward/mean: 1.67 metrics/optimality: 1.67
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ talet  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ lobos  │ 4.0    │ 4.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ lobos  │ 6.0    │ 6.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.18 | losses/policy_loss: -0.08 | losses/value_loss: 0.21]:  12%|██              | 100/800 [13:50<22:36:32, 116.28s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.06 | losses/value_loss: 0.18]:  13%|██▎               | 104/800 [14:08<5:55:03, 30.61s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.20 | losses/policy_loss: -0.06 | losses/value_loss: 0.22]:  14%|██▍               | 108/800 [14:25<1:56:07, 10.07s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.25 | losses/policy_loss: -0.06 | losses/value_loss: 0.26]:  14%|██▊                 | 112/800 [14:43<59:08,  5.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.24 | losses/policy_loss: -0.06 | losses/value_loss: 0.25]:  14%|██▉                 | 116/800 [15:03<50:24,  4.42s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.07 | losses/value_loss: 0.20]:  15%|███                 | 120/800 [15:24<48:05,  4.24s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.07 | losses/value_loss: 0.17]:  16%|███                 | 124/800 [15:45<47:21,  4.20s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.25 | losses/policy_loss: -0.05 | losses/value_loss: 0.25]:  16%|███▏                | 128/800 [16:03<43:33,  3.89s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.23 | losses/policy_loss: -0.06 | losses/value_loss: 0.24]:  16%|███▎                | 132/800 [16:24<45:48,  4.11s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.06 | losses/value_loss: 0.19]:  17%|███▍                | 136/800 [16:42<42:50,  3.87s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.07 | losses/value_loss: 0.13]:  18%|███▌                | 140/800 [17:00<40:19,  3.67s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.26 | losses/policy_loss: -0.06 | losses/value_loss: 0.26]:  18%|███▌                | 144/800 [17:19<41:05,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.26 | losses/policy_loss: -0.07 | losses/value_loss: 0.28]:  18%|███▋                | 148/800 [17:39<44:21,  4.08s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.06 | losses/value_loss: 0.15]:  19%|███▊                | 152/800 [17:58<41:44,  3.86s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.07 | losses/value_loss: 0.15]:  20%|███▉                | 156/800 [18:16<39:21,  3.67s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.29 | losses/policy_loss: -0.07 | losses/value_loss: 0.30]:  20%|████                | 160/800 [18:33<38:34,  3.62s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.05 | losses/value_loss: 0.16]:  20%|████                | 164/800 [18:52<39:43,  3.75s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.07 | losses/value_loss: 0.12]:  21%|████▏               | 168/800 [19:09<37:21,  3.55s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.06 | losses/value_loss: 0.16]:  22%|████▎               | 172/800 [19:28<39:01,  3.73s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.06 | losses/value_loss: 0.12]:  22%|████▍               | 176/800 [19:45<37:46,  3.63s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.06 | losses/value_loss: 0.19]:  22%|████▌               | 180/800 [20:06<41:52,  4.05s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.24 | losses/policy_loss: -0.05 | losses/value_loss: 0.24]:  23%|████▌               | 184/800 [20:23<38:06,  3.71s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.06 | losses/value_loss: 0.12]:  24%|████▋               | 188/800 [20:42<38:27,  3.77s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.04 | losses/value_loss: 0.18]:  24%|████▊               | 192/800 [21:00<36:54,  3.64s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.21 | losses/policy_loss: -0.05 | losses/value_loss: 0.22]:  24%|████▉               | 196/800 [21:17<36:21,  3.61s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.07 | losses/value_loss: 0.18]:  25%|████▉               | 199/800 [21:33<41:42,  4.16s/it][RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:07<00:00,  2.37s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                 Evaluation #2 reward/mean: 1.81 metrics/optimality: 1.81
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ bumps  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ lobos  │ 4.0    │ 4.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ golds  │ 2.0    │ 2.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.13 | losses/policy_loss: -0.07 | losses/value_loss: 0.17]:  25%|████            | 200/800 [27:55<19:32:56, 117.29s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.05 | losses/value_loss: 0.18]:  26%|████▌             | 204/800 [28:15<5:10:51, 31.29s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.05 | losses/value_loss: 0.16]:  26%|████▋             | 208/800 [28:35<1:45:27, 10.69s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.21 | losses/policy_loss: -0.05 | losses/value_loss: 0.22]:  26%|█████▎              | 212/800 [28:54<53:24,  5.45s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.19 | losses/policy_loss: -0.06 | losses/value_loss: 0.21]:  27%|█████▍              | 216/800 [29:12<40:46,  4.19s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.22 | losses/policy_loss: -0.05 | losses/value_loss: 0.22]:  28%|█████▌              | 220/800 [29:31<37:34,  3.89s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.06 | losses/value_loss: 0.11]:  28%|█████▌              | 224/800 [29:49<35:14,  3.67s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.05 | losses/value_loss: 0.19]:  28%|█████▋              | 228/800 [30:07<35:51,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.06 | losses/value_loss: 0.16]:  29%|█████▊              | 232/800 [30:24<33:37,  3.55s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.06 | losses/value_loss: 0.16]:  30%|█████▉              | 236/800 [30:43<35:05,  3.73s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.25 | losses/policy_loss: -0.06 | losses/value_loss: 0.26]:  30%|██████              | 240/800 [31:02<35:15,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.06 | losses/value_loss: 0.11]:  30%|██████              | 244/800 [31:20<35:06,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.06 | losses/value_loss: 0.16]:  31%|██████▏             | 248/800 [31:38<33:34,  3.65s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.06 | losses/value_loss: 0.14]:  32%|██████▎             | 252/800 [31:57<34:17,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.05 | losses/value_loss: 0.11]:  32%|██████▍             | 256/800 [32:14<33:00,  3.64s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.15 | losses/policy_loss: -0.02 | losses/value_loss: 0.14]:  32%|██████▌             | 260/800 [32:33<33:47,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.07 | losses/value_loss: 0.15]:  33%|██████▌             | 264/800 [32:51<32:31,  3.64s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.05 | losses/value_loss: 0.12]:  34%|██████▋             | 268/800 [33:09<33:17,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.05 | losses/value_loss: 0.13]:  34%|██████▊             | 272/800 [33:28<33:17,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.07 | losses/value_loss: 0.19]:  34%|██████▉             | 276/800 [33:46<33:05,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.25 | losses/policy_loss: -0.05 | losses/value_loss: 0.24]:  35%|███████             | 280/800 [34:05<32:51,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.15 | losses/policy_loss: -0.05 | losses/value_loss: 0.17]:  36%|███████             | 284/800 [34:24<32:36,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.08 | losses/value_loss: 0.15]:  36%|███████▏            | 288/800 [34:42<32:21,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.06 | losses/value_loss: 0.18]:  36%|███████▎            | 292/800 [35:01<32:07,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.07 | losses/value_loss: 0.16]:  37%|███████▍            | 296/800 [35:18<30:39,  3.65s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.04 | losses/value_loss: 0.15]:  37%|███████▍            | 299/800 [35:33<32:57,  3.95s/it][RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:07<00:00,  2.37s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                 Evaluation #3 reward/mean: 1.91 metrics/optimality: 1.91
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ tween  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ boors  │ 2.0    │ 2.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ boobs  │ 6.0    │ 6.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.13 | losses/policy_loss: -0.05 | losses/value_loss: 0.15]:  38%|██████          | 300/800 [41:53<16:13:35, 116.83s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.28 | losses/value_loss: 0.32]:  38%|██████▊           | 304/800 [42:14<4:18:04, 31.22s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.20 | losses/policy_loss: -0.03 | losses/value_loss: 0.20]:  38%|██████▉           | 308/800 [42:32<1:24:59, 10.37s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.07 | losses/value_loss: 0.15]:  39%|███████▊            | 312/800 [42:50<42:33,  5.23s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.10 | losses/value_loss: 0.23]:  40%|████████            | 320/800 [43:12<15:01,  1.88s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.06 | losses/value_loss: 0.11]:  40%|████████            | 324/800 [43:29<25:04,  3.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.06 | losses/value_loss: 0.17]:  41%|████████▏           | 328/800 [43:48<28:34,  3.63s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.04 | losses/value_loss: 0.13]:  42%|████████▎           | 332/800 [44:05<28:07,  3.61s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.05 | losses/value_loss: 0.17]:  42%|████████▍           | 336/800 [44:24<28:58,  3.75s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.05 | losses/value_loss: 0.13]:  42%|████████▌           | 340/800 [44:42<28:59,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.15 | losses/policy_loss: -0.07 | losses/value_loss: 0.18]:  43%|████████▌           | 344/800 [45:01<28:48,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.05 | losses/value_loss: 0.18]:  44%|████████▋           | 348/800 [45:19<27:28,  3.65s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.05 | losses/value_loss: 0.19]:  44%|████████▊           | 352/800 [45:37<28:02,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.06 | losses/value_loss: 0.20]:  44%|████████▉           | 356/800 [45:58<30:12,  4.08s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.05 | losses/value_loss: 0.18]:  45%|█████████           | 360/800 [46:18<30:31,  4.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.04 | losses/value_loss: 0.12]:  46%|█████████           | 364/800 [46:39<30:22,  4.18s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.27 | losses/policy_loss: -0.06 | losses/value_loss: 0.27]:  46%|█████████▏          | 368/800 [46:57<26:56,  3.74s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.06 | losses/policy_loss: -0.06 | losses/value_loss: 0.10]:  46%|█████████▎          | 372/800 [47:17<29:04,  4.08s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.05 | losses/value_loss: 0.11]:  47%|█████████▍          | 376/800 [47:38<29:24,  4.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.06 | losses/value_loss: 0.13]:  48%|█████████▌          | 380/800 [47:58<29:16,  4.18s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.02 | losses/policy_loss: -0.06 | losses/value_loss: 0.07]:  48%|█████████▌          | 384/800 [48:19<29:01,  4.19s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.05 | losses/value_loss: 0.19]:  48%|█████████▋          | 388/800 [48:40<28:44,  4.19s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.06 | losses/value_loss: 0.11]:  49%|█████████▊          | 392/800 [48:58<26:25,  3.89s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.05 | losses/value_loss: 0.16]:  50%|█████████▉          | 396/800 [49:16<24:43,  3.67s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.32 | losses/policy_loss: -0.05 | losses/value_loss: 0.31]:  50%|█████████▉          | 399/800 [49:31<27:00,  4.04s/it][RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:07<00:00,  2.37s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                 Evaluation #4 reward/mean: 2.12 metrics/optimality: 2.12
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ bumps  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ lobos  │ 4.0    │ 4.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ boons  │ 4.0    │ 4.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.30 | losses/policy_loss: -0.05 | losses/value_loss: 0.30]:  50%|████████        | 400/800 [55:48<12:52:21, 115.85s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.04 | losses/value_loss: 0.17]:  50%|█████████         | 404/800 [56:05<3:21:26, 30.52s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.27 | losses/policy_loss: -0.05 | losses/value_loss: 0.26]:  51%|█████████▏        | 408/800 [56:24<1:06:35, 10.19s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.06 | losses/value_loss: 0.14]:  52%|██████████▎         | 412/800 [56:42<34:28,  5.33s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.07 | losses/value_loss: 0.15]:  52%|██████████▍         | 416/800 [57:01<26:38,  4.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.06 | losses/value_loss: 0.15]:  52%|██████████▌         | 420/800 [57:19<23:39,  3.74s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.03 | losses/value_loss: 0.11]:  53%|██████████▌         | 424/800 [57:37<23:39,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.25 | losses/policy_loss: -0.06 | losses/value_loss: 0.26]:  54%|██████████▋         | 428/800 [57:54<22:02,  3.55s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.06 | losses/value_loss: 0.11]:  54%|██████████▊         | 432/800 [58:15<24:43,  4.03s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.21 | losses/policy_loss: -0.05 | losses/value_loss: 0.21]:  55%|██████████▉         | 436/800 [58:33<22:28,  3.71s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.03 | losses/value_loss: 0.14]:  55%|███████████         | 440/800 [58:51<22:36,  3.77s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.05 | losses/value_loss: 0.12]:  56%|███████████         | 444/800 [59:09<21:36,  3.64s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.05 | losses/value_loss: 0.12]:  56%|███████████▏        | 448/800 [59:29<23:46,  4.05s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.05 | losses/value_loss: 0.13]:  56%|███████████▎        | 452/800 [59:48<22:21,  3.86s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.06 | losses/value_loss: 0.13]:  57%|██████████▎       | 456/800 [1:00:06<21:00,  3.66s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.05 | losses/value_loss: 0.18]:  57%|██████████▎       | 460/800 [1:00:24<21:18,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.05 | losses/value_loss: 0.14]:  58%|██████████▍       | 464/800 [1:00:43<21:10,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.06 | losses/policy_loss: -0.06 | losses/value_loss: 0.10]:  58%|██████████▌       | 468/800 [1:01:01<20:57,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.05 | losses/policy_loss: -0.06 | losses/value_loss: 0.09]:  59%|██████████▌       | 472/800 [1:01:20<20:44,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.04 | losses/value_loss: 0.12]:  60%|██████████▋       | 476/800 [1:01:39<20:28,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.06 | losses/value_loss: 0.11]:  60%|██████████▊       | 480/800 [1:01:57<20:13,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.03 | losses/value_loss: 0.16]:  60%|██████████▉       | 484/800 [1:02:14<18:04,  3.43s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.05 | losses/value_loss: 0.13]:  61%|██████████▉       | 488/800 [1:02:31<18:29,  3.56s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.06 | losses/policy_loss: -0.07 | losses/value_loss: 0.11]:  62%|███████████       | 492/800 [1:02:50<19:09,  3.73s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.05 | losses/value_loss: 0.12]:  62%|███████████▏      | 496/800 [1:03:08<19:08,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.29 | losses/policy_loss: -0.04 | losses/value_loss: 0.27]:  62%|███████████▏      | 499/800 [1:03:24<21:10,  4.22s/it][RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:07<00:00,  2.37s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                 Evaluation #5 reward/mean: 2.26 metrics/optimality: 2.26
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ bumps  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ lobos  │ 4.0    │ 4.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ goups  │ 2.0    │ 2.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.28 | losses/policy_loss: -0.05 | losses/value_loss: 0.27]:  62%|█████████▍     | 500/800 [1:09:40<9:37:55, 115.59s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.06 | losses/value_loss: 0.20]:  63%|██████████      | 504/800 [1:09:58<2:30:52, 30.58s/it]K 0] Collecting rollouts
[losses/total_loss: 0.19 | losses/policy_loss: -0.03 | losses/value_loss: 0.19]:  64%|███████████▍      | 508/800 [1:10:16<49:41, 10.21s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.06 | losses/value_loss: 0.14]:  64%|███████████▌      | 512/800 [1:10:34<24:55,  5.19s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.07 | losses/value_loss: 0.17]:  64%|███████████▌      | 516/800 [1:10:53<19:33,  4.13s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.02 | losses/value_loss: 0.13]:  65%|███████████▋      | 520/800 [1:11:10<17:23,  3.73s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.28 | losses/policy_loss: -0.05 | losses/value_loss: 0.27]:  66%|███████████▊      | 524/800 [1:11:28<16:42,  3.63s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.24 | losses/policy_loss: -0.15 | losses/value_loss: 0.33]:  66%|███████████▉      | 528/800 [1:11:47<17:02,  3.76s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.06 | losses/value_loss: 0.12]:  66%|███████████▉      | 532/800 [1:12:05<16:54,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.18 | losses/value_loss: 0.23]:  67%|████████████      | 536/800 [1:12:26<18:09,  4.13s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.07 | losses/value_loss: 0.17]:  68%|████████████▏     | 540/800 [1:12:43<15:46,  3.64s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.07 | losses/value_loss: 0.12]:  68%|████████████▏     | 544/800 [1:13:02<16:00,  3.75s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.04 | losses/value_loss: 0.17]:  68%|████████████▎     | 548/800 [1:13:20<15:53,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.13 | losses/value_loss: 0.22]:  69%|████████████▍     | 552/800 [1:13:39<15:41,  3.80s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.04 | losses/value_loss: 0.10]:  70%|████████████▌     | 556/800 [1:13:57<14:49,  3.65s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.12 | losses/value_loss: 0.21]:  70%|████████████▌     | 560/800 [1:14:16<15:25,  3.85s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.30 | losses/policy_loss: -0.06 | losses/value_loss: 0.30]:  70%|████████████▋     | 564/800 [1:14:35<14:58,  3.81s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.06 | losses/value_loss: 0.18]:  71%|████████████▊     | 568/800 [1:14:53<14:41,  3.80s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.23 | losses/policy_loss: -0.05 | losses/value_loss: 0.23]:  72%|████████████▊     | 572/800 [1:15:12<14:25,  3.80s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.02 | losses/value_loss: 0.12]:  72%|████████████▉     | 576/800 [1:15:32<15:16,  4.09s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.07 | losses/value_loss: 0.14]:  72%|█████████████     | 580/800 [1:15:50<13:38,  3.72s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.05 | losses/policy_loss: -0.06 | losses/value_loss: 0.09]:  73%|█████████████▏    | 584/800 [1:16:08<13:04,  3.63s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.19 | losses/policy_loss: -0.05 | losses/value_loss: 0.20]:  74%|█████████████▏    | 588/800 [1:16:25<12:45,  3.61s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.19 | losses/policy_loss: -0.02 | losses/value_loss: 0.17]:  74%|█████████████▎    | 592/800 [1:16:44<12:59,  3.75s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.14 | losses/policy_loss: -0.05 | losses/value_loss: 0.16]:  74%|█████████████▍    | 596/800 [1:17:03<12:51,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.04 | losses/value_loss: 0.09]:  75%|█████████████▍    | 599/800 [1:17:18<13:39,  4.08s/it][RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:07<00:00,  2.37s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                 Evaluation #6 reward/mean: 2.43 metrics/optimality: 2.43
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ bunya  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ lobos  │ 4.0    │ 4.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ lobos  │ 6.0    │ 6.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.05 | losses/policy_loss: -0.06 | losses/value_loss: 0.09]:  75%|███████████▎   | 600/800 [1:23:35<6:27:10, 116.15s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.41 | losses/policy_loss: -0.09 | losses/value_loss: 0.42]:  76%|████████████    | 604/800 [1:23:54<1:40:40, 30.82s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.19 | losses/policy_loss: -0.06 | losses/value_loss: 0.20]:  76%|█████████████▋    | 608/800 [1:24:11<32:06, 10.04s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.07 | losses/value_loss: 0.13]:  76%|█████████████▊    | 612/800 [1:24:30<16:35,  5.29s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.19 | losses/policy_loss: -0.05 | losses/value_loss: 0.20]:  77%|█████████████▊    | 616/800 [1:24:48<12:44,  4.15s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.34 | losses/policy_loss: -0.10 | losses/value_loss: 0.37]:  78%|█████████████▉    | 620/800 [1:25:08<11:55,  3.97s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.03 | losses/value_loss: 0.18]:  78%|██████████████    | 624/800 [1:25:25<10:49,  3.69s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.06 | losses/value_loss: 0.15]:  78%|██████████████▏   | 628/800 [1:25:43<10:23,  3.62s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.02 | losses/value_loss: 0.09]:  80%|██████████████▎   | 636/800 [1:26:05<04:52,  1.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.06 | losses/value_loss: 0.15]:  80%|██████████████▍   | 640/800 [1:26:22<08:22,  3.14s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.05 | losses/value_loss: 0.14]:  80%|██████████████▍   | 644/800 [1:26:40<09:04,  3.49s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.02 | losses/value_loss: 0.17]:  81%|██████████████▌   | 648/800 [1:26:57<09:03,  3.58s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.04 | losses/value_loss: 0.12]:  82%|██████████████▋   | 652/800 [1:27:16<09:13,  3.74s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.05 | losses/policy_loss: -0.04 | losses/value_loss: 0.08]:  82%|██████████████▊   | 656/800 [1:27:37<09:47,  4.08s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.06 | losses/policy_loss: -0.05 | losses/value_loss: 0.09]:  82%|██████████████▊   | 660/800 [1:27:57<09:42,  4.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.07 | losses/value_loss: 0.17]:  83%|██████████████▉   | 664/800 [1:28:16<08:48,  3.88s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.05 | losses/value_loss: 0.17]:  84%|███████████████   | 668/800 [1:28:34<08:23,  3.81s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.22 | losses/value_loss: 0.32]:  84%|███████████████   | 672/800 [1:28:55<08:48,  4.13s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.18 | losses/value_loss: 0.24]:  84%|███████████████▏  | 676/800 [1:29:14<08:00,  3.88s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.24 | losses/policy_loss: -0.03 | losses/value_loss: 0.23]:  85%|███████████████▎  | 680/800 [1:29:32<07:37,  3.81s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.17 | losses/value_loss: 0.21]:  86%|███████████████▍  | 684/800 [1:29:52<07:32,  3.90s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.06 | losses/value_loss: 0.18]:  86%|███████████████▍  | 688/800 [1:30:10<07:07,  3.82s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.16 | losses/value_loss: 0.20]:  86%|███████████████▌  | 692/800 [1:30:29<07:00,  3.89s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.05 | losses/value_loss: 0.19]:  87%|███████████████▋  | 696/800 [1:30:48<06:36,  3.82s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.05 | losses/value_loss: 0.13]:  87%|███████████████▋  | 699/800 [1:31:03<06:53,  4.09s/it][RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████| 79/79 [03:07<00:00,  2.37s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                 Evaluation #7 reward/mean: 2.49 metrics/optimality: 2.49
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ pappa  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ foups  │ 2.0    │ 2.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ lobos  │ 6.0    │ 6.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.09 | losses/policy_loss: -0.05 | losses/value_loss: 0.12]:  88%|█████████████▏ | 700/800 [1:37:20<3:13:19, 115.99s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.16 | losses/policy_loss: -0.05 | losses/value_loss: 0.18]:  88%|███████████████▊  | 704/800 [1:37:40<49:34, 30.99s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.04 | losses/value_loss: 0.09]:  88%|███████████████▉  | 708/800 [1:37:58<15:35, 10.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.05 | losses/value_loss: 0.11]:  89%|████████████████  | 712/800 [1:38:17<07:48,  5.32s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.11 | losses/policy_loss: -0.05 | losses/value_loss: 0.14]:  90%|████████████████  | 716/800 [1:38:35<05:49,  4.16s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.06 | losses/value_loss: 0.10]:  90%|████████████████▏ | 720/800 [1:38:53<04:58,  3.74s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.13 | losses/policy_loss: -0.04 | losses/value_loss: 0.14]:  90%|████████████████▎ | 724/800 [1:39:11<04:47,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.06 | losses/value_loss: 0.13]:  91%|████████████████▍ | 728/800 [1:39:30<04:32,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.05 | losses/value_loss: 0.14]:  92%|████████████████▍ | 732/800 [1:39:49<04:17,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.09 | losses/policy_loss: -0.03 | losses/value_loss: 0.11]:  92%|████████████████▌ | 736/800 [1:40:07<04:02,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.10 | losses/policy_loss: -0.03 | losses/value_loss: 0.11]:  92%|████████████████▋ | 740/800 [1:40:26<03:47,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.15 | losses/policy_loss: -0.04 | losses/value_loss: 0.16]:  93%|████████████████▋ | 744/800 [1:40:46<03:49,  4.09s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.07 | losses/policy_loss: -0.04 | losses/value_loss: 0.09]:  94%|████████████████▊ | 748/800 [1:41:04<03:13,  3.72s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.24 | losses/policy_loss: -0.05 | losses/value_loss: 0.25]:  94%|████████████████▉ | 752/800 [1:41:22<02:54,  3.63s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.22 | losses/policy_loss: -0.05 | losses/value_loss: 0.22]:  94%|█████████████████ | 756/800 [1:41:40<02:44,  3.75s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.18 | losses/policy_loss: -0.05 | losses/value_loss: 0.19]:  95%|█████████████████ | 760/800 [1:41:59<02:31,  3.78s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.08 | losses/policy_loss: -0.05 | losses/value_loss: 0.11]:  96%|█████████████████▏| 764/800 [1:42:18<02:16,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.12 | losses/policy_loss: -0.05 | losses/value_loss: 0.15]:  96%|█████████████████▎| 768/800 [1:42:36<02:01,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.05 | losses/policy_loss: -0.06 | losses/value_loss: 0.09]:  96%|█████████████████▎| 772/800 [1:42:55<01:46,  3.79s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.06 | losses/policy_loss: -0.05 | losses/value_loss: 0.09]:  97%|█████████████████▍| 776/800 [1:43:15<01:38,  4.09s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.26 | losses/policy_loss: -0.20 | losses/value_loss: 0.38]:  98%|█████████████████▌| 780/800 [1:43:34<01:17,  3.87s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.32 | losses/policy_loss: -0.12 | losses/value_loss: 0.37]:  98%|█████████████████▋| 784/800 [1:43:55<01:06,  4.15s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.34 | losses/policy_loss: -0.05 | losses/value_loss: 0.33]:  98%|█████████████████▋| 788/800 [1:44:13<00:46,  3.88s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.20 | losses/policy_loss: -0.08 | losses/value_loss: 0.23]:  99%|█████████████████▊| 792/800 [1:44:32<00:30,  3.81s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.15 | losses/policy_loss: -0.04 | losses/value_loss: 0.16]: 100%|█████████████████▉| 796/800 [1:44:50<00:14,  3.65s/it][RANK 0] Collecting rollouts
[losses/total_loss: 0.17 | losses/policy_loss: -0.04 | losses/value_loss: 0.17]: 100%|█████████████████▉| 799/800 [1:45:05<00:04,  4.17s/it][RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/checkpoint_800
[RANK 0] Saving pretrained model into ckpts/checkpoint_800/hf_model
[RANK 0] Evaluating model
[generation sweep 1/1 | eval batch 37/79]:  46%|█████████████████████████████▏                                  | 36/79 [01:27<01:40,  2.34s[generation sweep 1/1 | eval batch 37/79]:  47%|█████████████████████████████▉                                  | 37/79 [01:27<01:38,  2.35s[generation sweep 1/1 | eval batch 38/79]:  47%|█████████████████████████████▉                                  | 37/79 [01:29<01:38,  2.35s[generation sweep 1/1 | eval batch 38/79]:  48%|██████████████████████████████▊                                 | 38/79 [01:29<01:35,  2.34s[generation sweep 1/1 | eval batch 39/79]:  48%|██████████████████████████████▊                                 | 38/79 [01:32<01:35,  2.34s[generation sweep 1/1 | eval batch 39/79]:  49%|███████████████████████████████▌                                | 39/79 [01:32<01:37,  2.44s[generation sweep 1/1 | eval batch 40/79]:  49%|███████████████████████████████▌                                | 39/79 [01:34<01:37,  2.44s[generation sweep 1/1 | eval batch 40/79]:  51%|████████████████████████████████▍                               | 40/79 [01:34<01:33,  2.40s[generation sweep 1/1 | eval batch 41/79]:  51%|████████████████████████████████▍                               | 40/79 [01:36<01:33,  2.40s[generation sweep 1/1 | eval batch 41/79]:  52%|█████████████████████████████████▏                              | 41/79 [01:36<01:30,  2.39s[generation sweep 1/1 | eval batch 42/79]:  52%|█████████████████████████████████▏                              | 41/79 [01:39<01:30,  2.39s[generation sweep 1/1 | eval batch 42/79]:  53%|██████████████████████████████████                              | 42/79 [01:39<01:27,  2.37s[generation sweep 1/1 | eval batch 43/79]:  53%|██████████████████████████████████                              | 42/79 [01:41<01:27,  2.37s[generation sweep 1/1 | eval batch 43/79]:  54%|██████████████████████████████████▊                             | 43/79 [01:41<01:24,  2.35s[generation sweep 1/1 | eval batch 44/79]:  54%|██████████████████████████████████▊                             | 43/79 [01:43<01:24,  2.35s[generation sweep 1/1 | eval batch 44/79]:  56%|███████████████████████████████████▋                            | 44/79 [01:43<01:25,  2.45s[generation sweep 1/1 | eval batch 45/79]:  56%|███████████████████████████████████▋                            | 44/79 [01:46<01:25,  2.45s[generation sweep 1/1 | eval batch 45/79]:  57%|████████████████████████████████████▍                           | 45/79 [01:46<01:22,  2.42s[generation sweep 1/1 | eval batch 46/79]:  57%|████████████████████████████████████▍                           | 45/79 [01:48<01:22,  2.42s[generation sweep 1/1 | eval batch 46/79]:  58%|█████████████████████████████████████▎                          | 46/79 [01:48<01:19,  2.41s[generation sweep 1/1 | eval batch 47/79]:  58%|█████████████████████████████████████▎                          | 46/79 [01:51<01:19,  2.41s[generation sweep 1/1 | eval batch 47/79]:  59%|██████████████████████████████████████                          | 47/79 [01:51<01:16,  2.39s[generation sweep 1/1 | eval batch 48/79]:  59%|██████████████████████████████████████                          | 47/79 [01:53<01:16,  2.39s[generation sweep 1/1 | eval batch 48/79]:  61%|██████████████████████████████████████▉                         | 48/79 [01:53<01:16,  2.48s[generation sweep 1/1 | eval batch 49/79]:  61%|██████████████████████████████████████▉                         | 48/79 [01:56<01:16,  2.48s[generation sweep 1/1 | eval batch 49/79]:  62%|███████████████████████████████████████▋                        | 49/79 [01:56<01:13,  2.44s[generation sweep 1/1 | eval batch 50/79]:  62%|███████████████████████████████████████▋                        | 49/79 [01:58<01:13,  2.44s[generation sweep 1/1 | eval batch 50/79]:  63%|████████████████████████████████████████▌                       | 50/79 [01:58<01:12,  2.51s[generation sweep 1/1 | eval batch 51/79]:  63%|████████████████████████████████████████▌                       | 50/79 [02:01<01:12,  2.51s[generation sweep 1/1 | eval batch 51/79]:  65%|█████████████████████████████████████████▎                      | 51/79 [02:01<01:08,  2.45s[generation sweep 1/1 | eval batch 52/79]:  65%|█████████████████████████████████████████▎                      | 51/79 [02:03<01:08,  2.45s[generation sweep 1/1 | eval batch 52/79]:  66%|██████████████████████████████████████████▏                     | 52/79 [02:03<01:05,  2.43s[generation sweep 1/1 | eval batch 53/79]:  66%|██████████████████████████████████████████▏                     | 52/79 [02:05<01:05,  2.43s[generation sweep 1/1 | eval batch 53/79]:  67%|██████████████████████████████████████████▉                     | 53/79 [02:05<01:02,  2.39s[generation sweep 1/1 | eval batch 54/79]:  67%|██████████████████████████████████████████▉                     | 53/79 [02:08<01:02,  2.39s[generation sweep 1/1 | eval batch 54/79]:  68%|███████████████████████████████████████████▋                    | 54/79 [02:08<01:01,  2.48s[generation sweep 1/1 | eval batch 55/79]:  68%|███████████████████████████████████████████▋                    | 54/79 [02:11<01:01,  2.48s[generation sweep 1/1 | eval batch 55/79]:  70%|████████████████████████████████████████████▌                   | 55/79 [02:11<01:00,  2.53s[generation sweep 1/1 | eval batch 56/79]:  70%|████████████████████████████████████████████▌                   | 55/79 [02:13<01:00,  2.53s[generation sweep 1/1 | eval batch 56/79]:  71%|█████████████████████████████████████████████▎                  | 56/79 [02:13<00:57,  2.48s[generation sweep 1/1 | eval batch 57/79]:  71%|█████████████████████████████████████████████▎                  | 56/79 [02:16<00:57,  2.48s[generation sweep 1/1 | eval batch 57/79]:  72%|██████████████████████████████████████████████▏                 | 57/79 [02:16<00:55,  2.54s[generation sweep 1/1 | eval batch 58/79]:  72%|██████████████████████████████████████████████▏                 | 57/79 [02:18<00:55,  2.54s[generation sweep 1/1 | eval batch 58/79]:  73%|██████████████████████████████████████████████▉                 | 58/79 [02:18<00:52,  2.49s[generation sweep 1/1 | eval batch 59/79]:  73%|██████████████████████████████████████████████▉                 | 58/79 [02:20<00:52,  2.49s[generation sweep 1/1 | eval batch 59/79]:  75%|███████████████████████████████████████████████▊                | 59/79 [02:20<00:48,  2.44s[generation sweep 1/1 | eval batch 60/79]:  75%|███████████████████████████████████████████████▊                | 59/79 [02:23<00:48,  2.44s[generation sweep 1/1 | eval batch 60/79]:  76%|████████████████████████████████████████████████▌               | 60/79 [02:23<00:45,  2.41s[generation sweep 1/1 | eval batch 61/79]:  76%|████████████████████████████████████████████████▌               | 60/79 [02:25<00:45,  2.41s[generation sweep 1/1 | eval batch 61/79]:  77%|█████████████████████████████████████████████████▍              | 61/79 [02:25<00:42,  2.38s[generation sweep 1/1 | eval batch 62/79]:  77%|█████████████████████████████████████████████████▍              | 61/79 [02:28<00:42,  2.38s[generation sweep 1/1 | eval batch 62/79]:  78%|██████████████████████████████████████████████████▏             | 62/79 [02:28<00:41,  2.47s[generation sweep 1/1 | eval batch 63/79]:  78%|██████████████████████████████████████████████████▏             | 62/79 [02:30<00:41,  2.47s[generation sweep 1/1 | eval batch 63/79]:  80%|███████████████████████████████████████████████████             | 63/79 [02:30<00:38,  2.44s[generation sweep 1/1 | eval batch 64/79]:  80%|███████████████████████████████████████████████████             | 63/79 [02:32<00:38,  2.44s[generation sweep 1/1 | eval batch 64/79]:  81%|███████████████████████████████████████████████████▊            | 64/79 [02:32<00:36,  2.40s[generation sweep 1/1 | eval batch 65/79]:  81%|███████████████████████████████████████████████████▊            | 64/79 [02:35<00:36,  2.40s[generation sweep 1/1 | eval batch 65/79]:  82%|████████████████████████████████████████████████████▋           | 65/79 [02:35<00:34,  2.48s[generation sweep 1/1 | eval batch 66/79]:  82%|████████████████████████████████████████████████████▋           | 65/79 [02:37<00:34,  2.48s[generation sweep 1/1 | eval batch 66/79]:  84%|█████████████████████████████████████████████████████▍          | 66/79 [02:37<00:31,  2.43s[generation sweep 1/1 | eval batch 67/79]:  84%|█████████████████████████████████████████████████████▍          | 66/79 [02:40<00:31,  2.43s[generation sweep 1/1 | eval batch 67/79]:  85%|██████████████████████████████████████████████████████▎         | 67/79 [02:40<00:28,  2.41s[generation sweep 1/1 | eval batch 68/79]:  85%|██████████████████████████████████████████████████████▎         | 67/79 [02:42<00:28,  2.41s[generation sweep 1/1 | eval batch 68/79]:  86%|███████████████████████████████████████████████████████         | 68/79 [02:42<00:26,  2.38s[generation sweep 1/1 | eval batch 69/79]:  86%|███████████████████████████████████████████████████████         | 68/79 [02:44<00:26,  2.38s[generation sweep 1/1 | eval batch 69/79]:  87%|███████████████████████████████████████████████████████▉        | 69/79 [02:44<00:23,  2.38s[generation sweep 1/1 | eval batch 70/79]:  87%|███████████████████████████████████████████████████████▉        | 69/79 [02:47<00:23,  2.38s[generation sweep 1/1 | eval batch 70/79]:  89%|████████████████████████████████████████████████████████▋       | 70/79 [02:47<00:21,  2.36s[generation sweep 1/1 | eval batch 71/79]:  89%|████████████████████████████████████████████████████████▋       | 70/79 [02:49<00:21,  2.36s[generation sweep 1/1 | eval batch 71/79]:  90%|█████████████████████████████████████████████████████████▌      | 71/79 [02:49<00:18,  2.35s[generation sweep 1/1 | eval batch 72/79]:  90%|█████████████████████████████████████████████████████████▌      | 71/79 [02:52<00:18,  2.35s[generation sweep 1/1 | eval batch 72/79]:  91%|██████████████████████████████████████████████████████████▎     | 72/79 [02:52<00:17,  2.44s[generation sweep 1/1 | eval batch 73/79]:  91%|██████████████████████████████████████████████████████████▎     | 72/79 [02:54<00:17,  2.44s[generation sweep 1/1 | eval batch 73/79]:  92%|███████████████████████████████████████████████████████████▏    | 73/79 [02:54<00:14,  2.42s[generation sweep 1/1 | eval batch 74/79]:  92%|███████████████████████████████████████████████████████████▏    | 73/79 [02:56<00:14,  2.42s[generation sweep 1/1 | eval batch 74/79]:  94%|███████████████████████████████████████████████████████████▉    | 74/79 [02:56<00:11,  2.39s[generation sweep 1/1 | eval batch 75/79]:  94%|███████████████████████████████████████████████████████████▉    | 74/79 [02:59<00:11,  2.39s[generation sweep 1/1 | eval batch 75/79]:  95%|████████████████████████████████████████████████████████████▊   | 75/79 [02:59<00:09,  2.38s[generation sweep 1/1 | eval batch 76/79]:  95%|████████████████████████████████████████████████████████████▊   | 75/79 [03:01<00:09,  2.38s[generation sweep 1/1 | eval batch 76/79]:  96%|█████████████████████████████████████████████████████████████▌  | 76/79 [03:01<00:07,  2.36s[generation sweep 1/1 | eval batch 77/79]:  96%|█████████████████████████████████████████████████████████████▌  | 76/79 [03:03<00:07,  2.36s[generation sweep 1/1 | eval batch 77/79]:  97%|██████████████████████████████████████████████████████████████▍ | 77/79 [03:03<00:04,  2.36s[generation sweep 1/1 | eval batch 78/79]:  97%|██████████████████████████████████████████████████████████████▍ | 77/79 [03:06<00:04,  2.36s[generation sweep 1/1 | eval batch 78/79]:  99%|███████████████████████████████████████████████████████████████▏| 78/79 [03:06<00:02,  2.35s[generation sweep 1/1 | eval batch 79/79]:  99%|███████████████████████████████████████████████████████████████▏| 78/79 [03:06<00:02,  2.35s[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████████| 79/79 [03:06<00:00,  1.74s[generation sweep 1/1 | eval batch 79/79]: 100%|████████████████████████████████████████████████████████████████| 79/79 [03:06<00:00,  2.36s/it]
[RANK 0] Computing rewards
[RANK 0] Computing metrics
[RANK 0] Summarizing evaluation
                                  Evaluation #8 reward/mean: 2.6 metrics/optimality: 2.6
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━┓
┃ prompt                                                                                  ┃ output ┃ reward ┃ optimality ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━┩
│ Please guess a word with five letters.                                                  │ tared  │ 0.0    │ 0.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: o. Absents letters: r,d,n.        │ foups  │ 2.0    │ 2.0        │
├─────────────────────────────────────────────────────────────────────────────────────────┼────────┼────────┼────────────┤
│ Please guess a word with five letters.Exists letters: s,o. Absents letters: e,n,r,d,u.  │ goups  │ 2.0    │ 2.0        │
└─────────────────────────────────────────────────────────────────────────────────────────┴────────┴────────┴────────────┘
[RANK 0] Saving intermediate optimizer & model checkpoint into ckpts/best_checkpoint
[RANK 0] Saving pretrained model into ckpts/best_checkpoint/hf_model
[losses/total_loss: 0.15 | losses/policy_loss: -0.05 | losses/value_loss: 0.16]: 100%|██████████████████| 800/800 [1:53:20<00:00,  8.50s/it]
wandb: Run history:
wandb:                kl_ctl_value ▁▁▁▁▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇██
wandb:       learning_rate_group_0 ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:          losses/policy_loss ▆▆▆▆▆▇▇▇▆▇▇▆▇▇▆▆▆▇▇▇▇▆▇▇▇▇▂▄██▇▇▇▁▇▇▇▇▇▇
wandb:           losses/total_loss ▄▅▃▅▂▃▄▄▁▄▂▁▂▂▂▂▂▃▄▁▄▁▂▁▂▂▂▂▂▃▃█▁▂▃▁▂▄▁▂
wandb:           losses/value_loss ▅▅▃▅▂▃▄▄▂▄▂▂▂▂▂▂▂▃▄▂▄▂▂▁▂▂▃▃▂▂▃█▁▅▃▁▁▄▁▂
wandb:          metrics/optimality ▁▅▆▆▇▇███
wandb:              old_values/max ▁▃▃▅▄▄▅▄▄▄▆▅▅▆▅▄▅▆▆▆▆▆▆▆▆▇▅▅▅▇▅▃█▆▇▆▆▅▆▅
wandb:             old_values/mean ▁▃▃▄▄▅▄▃▃▃▅▅▄▄▄▂▄▄▃▄▄▅▅▆▅▄▄▅▆▇▆▅▅▆▅▆█▇█▇
wandb:              old_values/min ▇▆▆▄▄▆▄▅▄▂▆▄▃▅▂▁▄▅▂▅▅▅▅▇▄▅▁▆█▅▅█▂▆▄▆▆▆▃▆
wandb:              old_values/std ▁▃▃▅▅▆▅▅▅▅▅▇▆▇▅▅▅▅▅▆▆▆▆▇▆▆▆▅▅▇▆▄▇▇▅▆█▆█▆
wandb:          padding_percentage ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁██▂▁▁▁▁█▁▁▁▁▁▁
wandb:            policy/approx_kl ▁▃▁▁▁▁▁▁▁▂▁▁▁▁▃▁▁▁▁▁▁▂▂▁▁▁▂▂▂▁▂▃▁█▁▁▁▁▂▁
wandb:             policy/clipfrac █▅▃▆▅▄▃▄▄▅▄▅▄▃▅▅▅▃▄▅▁▅▃▄▄▅▆▅▃▂▄▃▄▅▄▃▃▃▅▃
wandb:         policy/kl_per_token ▁▁▁▂▂▃▂▂▂▃▂▂▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂█▂▃▂▃▂▄▃▄▅▃▃▃
wandb:              policy/sqrt_kl ▁▁▁▂▂▃▂▂▂▃▂▂▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂█▂▃▂▃▂▅▃▄▅▃▃▃
wandb:                       ratio ▂▁▂▂▁▂▂▂▂▃▁▂▂▂▃▁▁▁▂▂▂▁▂▂▁▂▃▃▁▂▁▁▁█▁▁▁▂▃▁
wandb:                 returns/max ██▆██▆████▆▆▆██▆██▆▆██▆▆██▃▃▆█▆▆█▁██████
wandb:                returns/mean ▁▄▃▃▄▅▃▃▄▂▅▄▃▅▃▄▆▄▂▄▄▅▄▆▆▄▂▂▆▆▆▇▆▂▇▇█▆▇▇
wandb:                 returns/min ▅▇▅▃▅▃▄▅▅▄▅▅▇▇▄▅▇▅▁▅▁▆▄▅▅▆██▅▄▁▄▅█▅▇▇▅▄▇
wandb:                 returns/std ▅▆▅▆▅▆▅▆▅▅▅▅▄▆▅▅▆▆▅▅▆▆▅▆▆▅▁▁▅▆▇█▆▁▆▆▆▆▆▆
wandb:                 reward/mean ▁▅▆▆▇▇███
wandb:         rollout_scores/mean ▁▅▃▄▄▆▃▄▄▂▆▄▄▄▃▄▃▆▇▅▄▄▇▆▅▆▆▇▆▅▆▅▅▅▆▇█▅▇▇
wandb: rollout_scores/running_mean ▁▄▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇██████████
wandb:  rollout_scores/running_std ▂█▅▇▅▄▄▄▃▂▂▂▂▂▂▂▁▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▄▄
wandb:          rollout_scores/std ▄▅▄█▃▆▅▆▃▄▃▄▁▅▅▆▁▆▄▆▄▇▇▃▃█▂▅▆▆▆▄▆▅▆▅▅▇▆▆
wandb:               time/backward ▄▄▄▂▅▅▃▂▂▂▆▄▃▂▂▇▃▃▃▄▃▄▄█▂▃▃▂▄▃▃▁▃▃▂▂▂▅▃▇
wandb:                time/forward ▇▇█▇▆▇▇▇▆▇█▇▇▇▇▇▇▇▇▇▇██▇▇▇█▇█▇▇▁██▇▇▇▇█▇
wandb:               time/generate ▁█▇█▇▇▇█▄
wandb:                 time/metric ▁▇█▇▇███▇
wandb:       time/rollout_generate ▂▂█▂▂▁▂▂▂▂█▂▂▂▂▇▂▂██▂▂▂▂▂▂▂▂▃▂▃▂██▂▂▂▂█▂
wandb:          time/rollout_score ▁▃▃▂▁█▁▁▃▃█▄▄▄▃▄▄▄▃▃▂▃▄█▃▄▄▆▄▄▃▃▇▃▇▅▃▂▃▄
wandb:           time/rollout_time ▂▃█▃▁▁▃▃▁▂▇▂▂▂▃▇▂▂██▃▁▃▃▃▃▃▃▃▂▃▂██▃▃▃▂█▃
wandb:             values/clipfrac ▄▅▁▁▁▄▅▃▂▄▁▄▃▁▃▅▄▃▂▁▂▅▂▁▄▂▃▅▄▂▄█▁▇▁▂▁▁▃▄
wandb:                  values/max ▁▃▃▅▄▄▄▄▅▄▆▅▅▆▅▄▆▆▆▆▅▆▅▆▆▇▄▅▅▇▅▃█▅▆▆▅▅▆▅
wandb:                 values/mean ▁▄▃▄▄▅▄▄▄▂▅▄▄▅▃▄▅▄▃▅▅▅▅▆▆▄▄▅▆▇▆▇▆▅▅▇█▇██
wandb:                  values/min ▆▆▅▃▄▄▄▅▄▁▅▃▄▅▂▂▄▅▁▄▅▄▅▆▄▅▂▅▇▅▅█▂▄▄▅▅▆▂▆
wandb:                  values/std ▁▃▃▆▅▆▅▅▅▅▅▇▆▇▅▅▆▅▅▆▆▆▆▇▆▆▅▅▅█▆▅▇▆▅▇█▆█▆
wandb:         values/values_error ▅▅▃▅▂▃▄▄▂▄▂▂▂▂▂▂▂▃▄▂▄▂▂▁▂▂▃▃▂▂▃█▁▄▃▁▁▄▁▂
wandb:    values/values_mape_error ▅▂▃▆▂▂▂▄▃▄▆▂▅▂▃▁▂▂▁▃▁▁▁▁▁▁▁▂▁▁▁▁▁▂▁▁▁▁█▁
wandb:
wandb: Run summary:
wandb:                kl_ctl_value 0.01278
wandb:       learning_rate_group_0 0.0
wandb:          losses/policy_loss -0.04974
wandb:           losses/total_loss 0.14647
wandb:           losses/value_loss 0.16351
wandb:          metrics/optimality 2.5962
wandb:              old_values/max 3.34602
wandb:             old_values/mean 0.58812
wandb:              old_values/min -0.74801
wandb:              old_values/std 0.7744
wandb:          padding_percentage 0.0
wandb:            policy/approx_kl 0.03817
wandb:             policy/clipfrac 0.26562
wandb:         policy/kl_per_token 2.12273
wandb:              policy/sqrt_kl 14.70673
wandb:                       ratio 0.94149
wandb:                 returns/max 5.00696
wandb:                returns/mean 0.61154
wandb:                 returns/min -1.09129
wandb:                 returns/std 1.05581
wandb:                 reward/mean 2.5962
wandb:         rollout_scores/mean 2.60938
wandb: rollout_scores/running_mean 2.03444
wandb:  rollout_scores/running_std 3.1774
wandb:          rollout_scores/std 3.25804
wandb:               time/backward 0.01136
wandb:                time/forward 2.48519
wandb:               time/generate 186.57052
wandb:                 time/metric 0.03529
wandb:       time/rollout_generate 2.36284
wandb:          time/rollout_score 0.00233
wandb:           time/rollout_time 7.48444
wandb:             values/clipfrac 0.06771
wandb:                  values/max 3.54617
wandb:                 values/mean 0.62986
wandb:                  values/min -0.51744
wandb:                  values/std 0.81512
wandb:         values/values_error 0.32198
wandb:    values/values_mape_error 3.7838
